{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (9.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "\n",
    "# Path to chromedriver executable\n",
    "chromedriver_path = './chrome-win64/chromedriver.exe'\n",
    "# Path to chrome binary\n",
    "chrome_binary_path = './chrome-win64/chrome.exe'\n",
    "\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "options = Options()\n",
    "options.binary_location = chrome_binary_path\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Wait for the page to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "def download_image(url, path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "try:\n",
    "    for i in range(1, 2070):  # Adjust the range according to the maximum number of pages\n",
    "        page_url = f\"https://www.autogespot.com/spots/Switzerland/{i}\"\n",
    "        driver.get(page_url)\n",
    "        # Fetch the list of cars each time to avoid stale references\n",
    "        car_links = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//li/div[contains(@class, 'spot')]/a[contains(@class, 'cover-img-parent')]\")))\n",
    "        urls = [link.get_attribute('href') for link in car_links]\n",
    "        print(urls)\n",
    "\n",
    "        for url in urls:\n",
    "            driver.get(url)\n",
    "            try:\n",
    "                img_element = driver.find_element(By.XPATH, \"//article/ul/li/img\")\n",
    "                image_url = img_element.get_attribute(\"data-src\")\n",
    "                random_filename = f\"{uuid.uuid4()}.jpg\"\n",
    "                download_image(image_url, os.path.join('./images', random_filename))\n",
    "            except:\n",
    "                print(\"Error scraping: \" + url)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def download_image(image_url, image_directory, brand, car_name):\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            filename = f\"{brand}_{car_name}_{uuid.uuid4()}.jpg\"  # Integrate brand and car name into filename\n",
    "            filepath = os.path.join(image_directory, filename)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded {filepath}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {image_url}: Status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {image_url}: {str(e)}\")\n",
    "\n",
    "def process_page(page_url, image_directory):\n",
    "    try:\n",
    "        response = requests.get(page_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        car_spots = soup.find_all(\"div\", class_=\"bg-white p1 sm-p2 spot\")\n",
    "        \n",
    "        for spot in car_spots:\n",
    "            brand_model_element = spot.find(\"strong\", class_=\"truncate\")\n",
    "            if brand_model_element:\n",
    "                brand, car_name = [item.get_text(strip=True) for item in brand_model_element.find_all('a')]\n",
    "                spot_url = spot.find(\"a\", href=True)['href']\n",
    "                image_urls = fetch_image_urls_from_spot(spot_url)\n",
    "                if len(image_urls) != 0:\n",
    "                    for img_url in image_urls:\n",
    "                        download_image(img_url, image_directory, brand, car_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_url}: {str(e)}\")\n",
    "\n",
    "def fetch_image_urls_from_spot(spot_url):\n",
    "    try:\n",
    "        response = requests.get(spot_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        image_elements = soup.find_all(\"img\", attrs={\"data-src\": True, \"class\": \"photo\"})\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element[\"data-src\"])\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching images from {spot_url}: {str(e)}\")\n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithread\n",
    "base_url = \"https://www.autogespot.com/spots/Switzerland/\"\n",
    "image_directory = './images'\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "urls = [f\"{base_url}{i}\" for i in range(1, 2070)]  # Adjust range as necessary\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    executor.map(lambda url: process_page(url, image_directory), urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Thread\n",
    "base_url = \"https://www.autogespot.com/spots/Switzerland/\"\n",
    "image_directory = './images'\n",
    "os.makedirs(image_directory, exist_ok=True)\n",
    "urls = [f\"{base_url}{i}\" for i in range(1, 2070)]  # Adjust range as necessary\n",
    "\n",
    "for url in urls:\n",
    "    process_page(url, image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"processing_time\":62.547,\"results\":[{\"box\":{\"xmin\":1624,\"ymin\":1221,\"xmax\":1805,\"ymax\":1274},\"plate\":\"zh917866\",\"region\":{\"code\":\"ch\",\"score\":0.581},\"score\":0.9,\"candidates\":[{\"score\":0.9,\"plate\":\"zh917866\"}],\"dscore\":0.764,\"vehicle\":{\"score\":0.968,\"type\":\"Sedan\",\"box\":{\"xmin\":394,\"ymin\":584,\"xmax\":2097,\"ymax\":1365}}}],\"filename\":\"1845_X2VXj_ferrari-812-gts-c830110042024004411_1.jpg\",\"version\":1,\"camera_id\":null,\"timestamp\":\"2024-04-10T18:45:35.026088Z\"}\n",
      "zh917866\n"
     ]
    }
   ],
   "source": [
    "def get_license_plate_number(image_url, api_token):\n",
    "    api_endpoint = 'https://api.platerecognizer.com/v1/plate-reader/'\n",
    "    headers = {'Authorization': f'Token {api_token}'}\n",
    "    data = {'upload_url': image_url, 'regions': 'ch'}\n",
    "    try:\n",
    "        response = requests.post(api_endpoint, headers=headers, data=data)\n",
    "        response.raise_for_status()\n",
    "        print(response.text)\n",
    "        plates_data = response.json()\n",
    "        return plates_data['results'][0]['plate'] if plates_data['results'] else None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "api_token = '...'  # Replace with your actual API token\n",
    "image_url = 'https://spots.ag/2024/04/10/ferrari-812-gts-c830110042024004411_1.jpg?1712702690'\n",
    "plate_number = get_license_plate_number(image_url, api_token)\n",
    "print(plate_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_license_plate_number(image_url, api_token):\n",
    "    api_endpoint = 'https://api.platerecognizer.com/v1/plate-reader/'\n",
    "    headers = {'Authorization': f'Token {api_token}'}\n",
    "    data = {'upload_url': image_url, 'regions': 'ch'}\n",
    "    try:\n",
    "        response = requests.post(api_endpoint, headers=headers, data=data)\n",
    "        response.raise_for_status()\n",
    "        print(response.text)\n",
    "        plates_data = response.json()\n",
    "        return plates_data['results'][0]['plate'] if plates_data['results'] else None\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def compress_image(image_bytes, max_size_mb=3, step=5, quality=85):\n",
    "    img = Image.open(image_bytes)\n",
    "    while image_bytes.getbuffer().nbytes > (max_size_mb * 1024 * 1024):\n",
    "        img = img.resize((int(img.width * (100 - step) / 100), int(img.height * (100 - step) / 100)))\n",
    "        image_bytes = BytesIO()\n",
    "        img.save(image_bytes, format='JPEG', quality=quality)\n",
    "    return image_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_license_plate_number_bytes(image_bytes, api_token):\n",
    "    time.sleep(1)\n",
    "    api_endpoint = 'https://api.platerecognizer.com/v1/plate-reader/'\n",
    "    headers = {'Authorization': f'Token {api_token}'}\n",
    "    files = {'upload': ('image.jpg', image_bytes, 'image/jpeg')}  # Assume the image is JPEG\n",
    "    data = {'regions': 'ch'}\n",
    "    try:\n",
    "        response = requests.post(api_endpoint, headers=headers, files=files, data=data)\n",
    "        response.raise_for_status()\n",
    "        print(response.text)\n",
    "        plates_data = response.json()\n",
    "        return plates_data['results'][0]['plate'] if plates_data['results'] else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create excel sheet with brand, model, license plate\n",
    "\n",
    "'''\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def process_page(page_url, car_details, api_token):\n",
    "    try:\n",
    "        response = requests.get(page_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        car_spots = soup.find_all(\"div\", class_=\"bg-white p1 sm-p2 spot\")\n",
    "        \n",
    "        for spot in car_spots:\n",
    "            brand_model_element = spot.find(\"strong\", class_=\"truncate\")\n",
    "            if brand_model_element:\n",
    "                brand, car_name = [item.get_text(strip=True) for item in brand_model_element.find_all('a')]\n",
    "                spot_url = spot.find(\"a\", href=True)['href']\n",
    "                preview_url = spot.find(\"img\")['src']\n",
    "                preview_bytes = download_image(preview_url)\n",
    "                #image_url = fetch_image_urls_from_spot(spot_url)[0]\n",
    "                #image_bytes = compress_image(download_image(image_url))\n",
    "\n",
    "                #Get license plate from preview\n",
    "                img_url = preview_url\n",
    "                license_plate = get_license_plate_number_bytes(preview_bytes, api_token)\n",
    "\n",
    "                car_details.append({\n",
    "                    \"Brand\": brand,\n",
    "                    \"Model\": car_name,\n",
    "                    \"Image URL\": img_url,\n",
    "                    \"Spot URL\": spot_url,\n",
    "                    \"License Plate\": license_plate\n",
    "                })\n",
    "                # Write to Excel file periodically or after adding each entry\n",
    "                df = pd.DataFrame(car_details)\n",
    "                df.to_excel('car_details.xlsx', index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_url}: {str(e)}\")\n",
    "\n",
    "def fetch_image_urls_from_spot(spot_url):\n",
    "    try:\n",
    "        response = requests.get(spot_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        image_elements = soup.find_all(\"img\", attrs={\"data-src\": True, \"class\": \"photo\"})\n",
    "        return [image_element[\"data-src\"] for image_element in image_elements]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching images from {spot_url}: {str(e)}\")\n",
    "    return []\n",
    "\n",
    "# Main processing\n",
    "base_url = \"https://www.autogespot.com/spots/Switzerland/\"\n",
    "car_details = []\n",
    "api_token = \"...\"  # Replace with your actual API token\n",
    "\n",
    "# Process pages in a loop\n",
    "for i in range(1, 2070):  # Adjust range as necessary\n",
    "    url = f\"{base_url}{i}\"\n",
    "    process_page(url, car_details, api_token)\n",
    "\n",
    "# Write to Excel after completing all pages as a final save\n",
    "df = pd.DataFrame(car_details)\n",
    "df.to_excel('car_details.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
